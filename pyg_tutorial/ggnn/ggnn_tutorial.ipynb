{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ggnn_tutorial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO2eLJZZ/U+s2miAVWfXYSO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e1432ed7f2654fc8892ea1d1b1fd88ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c2d3edcdac74e879d7f4225c2c0794f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d8f20a4cb901410eb7fb8975ad69e8a6","IPY_MODEL_648b912362d44ee0907379eae092317b","IPY_MODEL_0201daf9e0484d4b9da8918e42540778"]}},"4c2d3edcdac74e879d7f4225c2c0794f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8f20a4cb901410eb7fb8975ad69e8a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3c4602ce571499aa4a4fc09c2a6d31a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f22ac74cfa747be8543bf1a1453f67b"}},"648b912362d44ee0907379eae092317b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_067fc774a69d4062aa76a171d75b0f20","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa5960a125f94d04a801977a61c1eeec"}},"0201daf9e0484d4b9da8918e42540778":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0b3ce57d59a440390916f24dc06379e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [02:02&lt;00:00,  8.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b041586a63f4dc59926550056d50e9a"}},"f3c4602ce571499aa4a4fc09c2a6d31a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f22ac74cfa747be8543bf1a1453f67b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"067fc774a69d4062aa76a171d75b0f20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fa5960a125f94d04a801977a61c1eeec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0b3ce57d59a440390916f24dc06379e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b041586a63f4dc59926550056d50e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a04c59cbdfe45e5b1202daade48c347":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9915770d343c456081a851cb95ff9ab0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b35495112bb480d9b38ffa80304dd76","IPY_MODEL_385d00747945426883f82dea01ff8249","IPY_MODEL_aefe10969ed643efbfc9b99f28f0b2f8"]}},"9915770d343c456081a851cb95ff9ab0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b35495112bb480d9b38ffa80304dd76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0293d7093d954a5e9a301d0e55e85397","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93bffcbb38fb497f8a96001da8f9e3de"}},"385d00747945426883f82dea01ff8249":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_afe8cc0edb9748118e87e14461921203","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64685cfeaf8f42d6b14ef37a574f4dad"}},"aefe10969ed643efbfc9b99f28f0b2f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee9218dd33194f9d81e6ce491a41c22e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [03:12&lt;00:00,  2.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a791df7321734d24bd33fb6b839399b5"}},"0293d7093d954a5e9a301d0e55e85397":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"93bffcbb38fb497f8a96001da8f9e3de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afe8cc0edb9748118e87e14461921203":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"64685cfeaf8f42d6b14ef37a574f4dad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee9218dd33194f9d81e6ce491a41c22e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a791df7321734d24bd33fb6b839399b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOneaSZgPZAV","cellView":"form","executionInfo":{"status":"ok","timestamp":1629822095127,"user_tz":-540,"elapsed":15841,"user":{"displayName":"변호윤","photoUrl":"","userId":"00199062537959239199"}},"outputId":"0d3f8a8b-a452-4c7e-b7bf-2600e3697a0e"},"source":["#@title PyG 실습에 필요한 패키지 설치\n","# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n","import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","print(TORCH)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","print(CUDA)\n","\n","!pip install torch-scatter     -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -q -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install -q torch-geometric"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.9.0\n","cu102\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FMm_F1PPQNml"},"source":["import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch_geometric\n","import torch_geometric.transforms as T\n","\n","from tqdm import tqdm_notebook as tqdm\n","\n","from torch import Tensor\n","from torch.nn import Parameter as Param\n","from torch_geometric.datasets import Planetoid, TUDataset\n","from torch_geometric.data import DataLoader\n","from torch_geometric.nn.inits import uniform\n","from torch_geometric.nn.conv import MessagePassing\n","\n","torch.manual_seed(42)\n","device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcgBuveJUPIN"},"source":["dataset = 'Cora'\n","\n","path = os.path.join('.','data', dataset)\n","dataset = Planetoid(path, dataset)\n","data = dataset[0]\n","data = data.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kBILEuwjxJIx"},"source":["### GNNM\n","\n","$$\n","x_v^{t+1}=f_w(l_v,l_{co(v)},x_{ne(v)}^t,l_{ne(v)}) \\\\\n","o_v^t = g_w(x_v^t,l_v)\n","$$\n","\n"]},{"cell_type":"code","metadata":{"id":"XC7cY34PVGfo"},"source":["class MLP(nn.Module):\n","    '''\n","    dims = [input, hid, hid, hid, out]\n","    0 Linear(input, hid)\n","    0 Tanh\n","    1 Linear(hid, hid)\n","    1 Tanh\n","    2 Linear(hid, hid)\n","    2 Tanh\n","    3 Linear(hid, out)\n","    => propagation : node state (node featrue)\n","    => output : node score (이후 softmax 적용)\n","    '''\n","    def __init__(self, input_dim, hid_dims, out_dim):\n","        super(MLP, self).__init__()\n","\n","        self.mlp = nn.Sequential()\n","        dims = [input_dim] + hid_dims + [out_dim]\n","        for i in range(len(dims)-1):\n","            self.mlp.add_module('lay_{}'.format(i), nn.Linear(in_features=dims[i], out_features=dims[i+1]))\n","            if i+2 < len(dims):\n","                self.mlp.add_module('drop_{}'.format(i), nn.Dropout())\n","                self.mlp.add_module('act_{}'.format(i), nn.Tanh())\n","            \n","    def reset_parameters(self):\n","        for i, l in enumerate(self.mlp):\n","            if type(l) == nn.Linear:\n","                nn.init.xavier_normal_(l.weight)\n","    \n","    def forward(self, x):\n","        return self.mlp(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiARMQz5zIu2"},"source":["class GNNM(MessagePassing):\n","    def __init__(self, n_nodes, out_channels, features_dim, hid_dims,\n","                 max_iter=50, eps=1e-3, aggr='add', bias=True, **kwargs):\n","        super(GNNM, self).__init__(aggr=aggr, **kwargs)\n","\n","        self.node_states = Param(torch.zeros((n_nodes, features_dim)), requires_grad=False)\n","        self.out_channels = out_channels\n","        self.eps = eps # contraction map\n","        self.max_iter = max_iter\n","\n","        self.transition = MLP(features_dim, hid_dims, features_dim)\n","        self.readout = MLP(features_dim, hid_dims, out_channels)\n","\n","        self.reset_paramters()\n","        print(self.transition)\n","        print(self.readout)\n","\n","    def reset_paramters(self):\n","        self.transition.reset_parameters()\n","        self.readout.reset_parameters()\n","    \n","    def forward(self):\n","        edge_index = data.edge_index\n","        edge_weight = data.edge_attr\n","        node_states = self.node_states # 0으로 초기화된 x(0) : node feature matrix\n","\n","        # Forward - repeat(max_iter는 최대 iteration)\n","        for i in range(self.max_iter):\n","            m = self.propagate(edge_index, x=node_states, edge_weight=edge_weight,\n","                               size=None)\n","            new_states = self.transition(m)\n","            \n","            with torch.no_grad():\n","                distance = torch.norm(new_states-node_states, dim=1)\n","                convergence = distance < self.eps\n","            node_states = new_states\n","            if convergence.all():\n","                break\n","        \n","        out = self.readout(node_states)\n","\n","        return F.log_softmax(out, dim=-1)\n","    \n","    def message(self, x_j, edge_weight):\n","        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n","    \n","    def message_and_aggregate(self, adj_t, x):\n","        # 이 메소드 사용 안됨\n","        return matmul(adj_t, x, reduce=self.aggr)\n","    \n","    def __repr__(self):\n","        return '{}({}, num_layers={})'.format(self.__class__.name__,\n","                                              self.out_channels,\n","                                              self.num_layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBOvoOHI3hdC","executionInfo":{"status":"ok","timestamp":1629822100621,"user_tz":-540,"elapsed":11,"user":{"displayName":"변호윤","photoUrl":"","userId":"00199062537959239199"}},"outputId":"a745f502-9425-458e-c1a0-96066027a3df"},"source":["lr = 0.001\n","EPOCHS = 1000\n","\n","num_nodes = data.num_nodes\n","num_classes = dataset.num_classes\n","features_dim = 32\n","hid_dims = [64,64,64,64,64]\n","max_iter = 100\n","eps=0.01\n","\n","print(f'# of nodes : {num_nodes}')\n","print(f'# of classes : {num_classes}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# of nodes : 2708\n","# of classes : 7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4W681bta2mSp","executionInfo":{"status":"ok","timestamp":1629822100621,"user_tz":-540,"elapsed":8,"user":{"displayName":"변호윤","photoUrl":"","userId":"00199062537959239199"}},"outputId":"e3ee0a95-f064-4d5b-e6ae-158938b08f33"},"source":["model = GNNM(n_nodes=num_nodes, out_channels=num_classes,\n","             features_dim=features_dim,\n","             hid_dims=hid_dims, eps=eps).to(device)\n","opt = torch.optim.Adam(model.parameters(), lr=lr)\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MLP(\n","  (mlp): Sequential(\n","    (lay_0): Linear(in_features=32, out_features=64, bias=True)\n","    (drop_0): Dropout(p=0.5, inplace=False)\n","    (act_0): Tanh()\n","    (lay_1): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_1): Dropout(p=0.5, inplace=False)\n","    (act_1): Tanh()\n","    (lay_2): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_2): Dropout(p=0.5, inplace=False)\n","    (act_2): Tanh()\n","    (lay_3): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_3): Dropout(p=0.5, inplace=False)\n","    (act_3): Tanh()\n","    (lay_4): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_4): Dropout(p=0.5, inplace=False)\n","    (act_4): Tanh()\n","    (lay_5): Linear(in_features=64, out_features=32, bias=True)\n","  )\n",")\n","MLP(\n","  (mlp): Sequential(\n","    (lay_0): Linear(in_features=32, out_features=64, bias=True)\n","    (drop_0): Dropout(p=0.5, inplace=False)\n","    (act_0): Tanh()\n","    (lay_1): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_1): Dropout(p=0.5, inplace=False)\n","    (act_1): Tanh()\n","    (lay_2): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_2): Dropout(p=0.5, inplace=False)\n","    (act_2): Tanh()\n","    (lay_3): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_3): Dropout(p=0.5, inplace=False)\n","    (act_3): Tanh()\n","    (lay_4): Linear(in_features=64, out_features=64, bias=True)\n","    (drop_4): Dropout(p=0.5, inplace=False)\n","    (act_4): Tanh()\n","    (lay_5): Linear(in_features=64, out_features=7, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XGSqxOoioYsZ"},"source":["def train():\n","    model.train()\n","    opt.zero_grad()\n","    loss_fn(model()[data.train_mask], data.y[data.train_mask]).backward()\n","    opt.step()\n","\n","def test():\n","    model.eval()\n","    logits, accs = model(), []\n","    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n","        pred = logits[mask].max(1)[1]\n","        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    return accs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270,"referenced_widgets":["e1432ed7f2654fc8892ea1d1b1fd88ab","4c2d3edcdac74e879d7f4225c2c0794f","d8f20a4cb901410eb7fb8975ad69e8a6","648b912362d44ee0907379eae092317b","0201daf9e0484d4b9da8918e42540778","f3c4602ce571499aa4a4fc09c2a6d31a","0f22ac74cfa747be8543bf1a1453f67b","067fc774a69d4062aa76a171d75b0f20","fa5960a125f94d04a801977a61c1eeec","b0b3ce57d59a440390916f24dc06379e","2b041586a63f4dc59926550056d50e9a"]},"id":"JR9tXVwXpgsW","executionInfo":{"status":"ok","timestamp":1629822223327,"user_tz":-540,"elapsed":122712,"user":{"displayName":"변호윤","photoUrl":"","userId":"00199062537959239199"}},"outputId":"663b4966-d191-4f6f-c612-5334fa4ed76b"},"source":["for epoch in tqdm(range(EPOCHS)):\n","    train()\n","\n","    if (epoch % 100) == 0:\n","        accs = test()\n","        train_acc = accs[0]\n","        val_acc = accs[1]\n","        test_acc = accs[2]\n","        print(f\"Epoch: {epoch+100}, Train Acc : {train_acc:.3f}, Val Acc : {val_acc:.3f}, Test Acc : {test_acc:.3f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1432ed7f2654fc8892ea1d1b1fd88ab","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","text":["Epoch: 100, Train Acc : 0.114, Val Acc : 0.144, Test Acc : 0.148\n","Epoch: 200, Train Acc : 0.150, Val Acc : 0.116, Test Acc : 0.121\n","Epoch: 300, Train Acc : 0.186, Val Acc : 0.118, Test Acc : 0.131\n","Epoch: 400, Train Acc : 0.143, Val Acc : 0.092, Test Acc : 0.100\n","Epoch: 500, Train Acc : 0.157, Val Acc : 0.096, Test Acc : 0.100\n","Epoch: 600, Train Acc : 0.136, Val Acc : 0.088, Test Acc : 0.093\n","Epoch: 700, Train Acc : 0.150, Val Acc : 0.152, Test Acc : 0.145\n","Epoch: 800, Train Acc : 0.143, Val Acc : 0.310, Test Acc : 0.317\n","Epoch: 900, Train Acc : 0.129, Val Acc : 0.232, Test Acc : 0.232\n","Epoch: 1000, Train Acc : 0.129, Val Acc : 0.124, Test Acc : 0.123\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NnYZw4C7tkkR"},"source":["### Gated Graph Neural Network"]},{"cell_type":"markdown","metadata":{"id":"yVQ7XQOw5V3F"},"source":["\\begin{align}\\begin{aligned}\\mathbf{h}_i^{(0)} &= \\mathbf{x}_i \\, \\Vert \\, \\mathbf{0}\\\\\\mathbf{m}_i^{(l+1)} &= \\sum_{j \\in \\mathcal{N}(i)} e_{j,i} \\cdot\n","\\mathbf{\\Theta} \\cdot \\mathbf{h}_j^{(l)}\\\\\\mathbf{h}_i^{(l+1)} &= \\textrm{GRU} (\\mathbf{m}_i^{(l+1)},\n","\\mathbf{h}_i^{(l)})\\end{aligned}\\end{align}"]},{"cell_type":"code","metadata":{"id":"82N15n5dqPtx"},"source":["class GatedGraphConv(MessagePassing):\n","    def __init__(self, out_channels, num_layers, aggr='add',\n","                 bias=True, **kwargs):\n","        super(GatedGraphConv, self).__init__(aggr=aggr, **kwargs)\n","\n","        self.out_channels = out_channels\n","        self.num_layers = num_layers\n","\n","        self.weight = Param(Tensor(num_layers, out_channels, out_channels))\n","        self.rnn = torch.nn.GRUCell(input_size=out_channels,\n","                                    hidden_size=out_channels,\n","                                    bias=bias)\n","        self.reset_parameters()\n","    \n","    def reset_parameters(self):\n","        \n","        # bound = 1.0 / math.sqrt(out_channels)\n","        # tensor.data.uniform_(-bound, bound)\n","        \n","        uniform(self.out_channels, self.weight)\n","        self.rnn.reset_parameters()\n","    \n","    def forward(self, data):\n","        #-(x -init-> h)------------------------------------------------------#\n","        x = data.x\n","        edge_index = data.edge_index\n","        edge_weight = data.edge_attr\n","\n","        if x.size(-1) > self.out_channels:\n","            raise ValueError('The number of input channels is not allowed to\\\n","            \\n be larger than the number of output channels')\n","        \n","        if x.size(-1) < self.out_channels:\n","            zero = x.new_zeros(x.size(0), self.out_channels - x.size(-1))\n","            x = torch.cat([x, zero], dim=1)\n","        #-------------------------------------------------------------------#\n","        for i in range(self.num_layers):\n","            \n","            m = torch.matmul(x, self.weight[i])\n","\n","            # propagate and GRU\n","            # (h -> a)\n","            m = self.propagate(edge_index, x=m, edge_weight=edge_weight,\n","                               size=None)\n","            x = self.rnn(m, x)\n","        \n","        return x\n","    \n","    def message(self, x_j, edge_weight):\n","        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n","    \n","    def message_and_aggregate(self, adj_t, x):\n","        return matmul(adj_t, x, reduce=self.aggr)\n","    \n","    def __repr__(self):\n","        return '{}({}, num_layers={})'.format(self.__class__.__name__,\n","                                              self.out_channels,\n","                                              self.num_layers)\n","        \n","class GGNN(torch.nn.Module):\n","    def __init__(self, input_dim, hid_dims, out_dim, num_layers):\n","        super(GGNN, self).__init__()\n","        self.conv = GatedGraphConv(input_dim, num_layers)\n","        self.mlp = MLP(input_dim, hid_dims, out_dim)\n","    \n","    def forward(self):\n","        x = self.conv(data)\n","        x = self.mlp(x)\n","        return F.log_softmax(x, dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVgOtxhp_2OU"},"source":["lr=0.0001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":933,"referenced_widgets":["6a04c59cbdfe45e5b1202daade48c347","9915770d343c456081a851cb95ff9ab0","2b35495112bb480d9b38ffa80304dd76","385d00747945426883f82dea01ff8249","aefe10969ed643efbfc9b99f28f0b2f8","0293d7093d954a5e9a301d0e55e85397","93bffcbb38fb497f8a96001da8f9e3de","afe8cc0edb9748118e87e14461921203","64685cfeaf8f42d6b14ef37a574f4dad","ee9218dd33194f9d81e6ce491a41c22e","a791df7321734d24bd33fb6b839399b5"]},"id":"7TW3cKS-xjRG","executionInfo":{"status":"ok","timestamp":1629823726454,"user_tz":-540,"elapsed":192881,"user":{"displayName":"변호윤","photoUrl":"","userId":"00199062537959239199"}},"outputId":"f11471bc-a676-459f-9ce3-9444b7d34570"},"source":["model = GGNN(input_dim=data.num_features,\n","             hid_dims=[32,32,32],\n","             out_dim=dataset.num_classes,\n","             num_layers=3).to(device)\n","\n","opt = torch.optim.Adam(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.5)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def train():\n","    model.train()\n","    opt.zero_grad()\n","    loss_fn(model()[data.train_mask], data.y[data.train_mask]).backward()\n","    opt.step()\n","    scheduler.step()\n","\n","def test():\n","    model.eval()\n","    logits, accs = model(), []\n","    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n","        pred = logits[mask].max(1)[1]\n","        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    return accs\n","\n","\n","for epoch in tqdm(range(500)):\n","    train()\n","    \n","    if (epoch % 10) == 0:\n","        accs = test()\n","        train_acc = accs[0]\n","        val_acc = accs[1]\n","        test_acc = accs[2]\n","        print('Epoch: {:03d}, Train Acc: {:.5f}, '\n","                'Val Acc: {:.5f}, Test Acc: {:.5f}'.format(epoch, train_acc,\n","                                                            val_acc, test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a04c59cbdfe45e5b1202daade48c347","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","text":["Epoch: 000, Train Acc: 0.17857, Val Acc: 0.17200, Test Acc: 0.15600\n","Epoch: 010, Train Acc: 0.65000, Val Acc: 0.56200, Test Acc: 0.55400\n","Epoch: 020, Train Acc: 0.77857, Val Acc: 0.70600, Test Acc: 0.67500\n","Epoch: 030, Train Acc: 0.86429, Val Acc: 0.73400, Test Acc: 0.69700\n","Epoch: 040, Train Acc: 0.90000, Val Acc: 0.74600, Test Acc: 0.70600\n","Epoch: 050, Train Acc: 0.93571, Val Acc: 0.74600, Test Acc: 0.70800\n","Epoch: 060, Train Acc: 0.95714, Val Acc: 0.75600, Test Acc: 0.71400\n","Epoch: 070, Train Acc: 0.95714, Val Acc: 0.76000, Test Acc: 0.72000\n","Epoch: 080, Train Acc: 0.95714, Val Acc: 0.75400, Test Acc: 0.71400\n","Epoch: 090, Train Acc: 0.96429, Val Acc: 0.75000, Test Acc: 0.71400\n","Epoch: 100, Train Acc: 0.97143, Val Acc: 0.74800, Test Acc: 0.71300\n","Epoch: 110, Train Acc: 0.97143, Val Acc: 0.75000, Test Acc: 0.71800\n","Epoch: 120, Train Acc: 0.97143, Val Acc: 0.75400, Test Acc: 0.72000\n","Epoch: 130, Train Acc: 0.97143, Val Acc: 0.74800, Test Acc: 0.72200\n","Epoch: 140, Train Acc: 0.97857, Val Acc: 0.75200, Test Acc: 0.72200\n","Epoch: 150, Train Acc: 0.97857, Val Acc: 0.74200, Test Acc: 0.71300\n","Epoch: 160, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71400\n","Epoch: 170, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71600\n","Epoch: 180, Train Acc: 0.97857, Val Acc: 0.74800, Test Acc: 0.71900\n","Epoch: 190, Train Acc: 0.97857, Val Acc: 0.74800, Test Acc: 0.71900\n","Epoch: 200, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 210, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 220, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71800\n","Epoch: 230, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 240, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 250, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 260, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 270, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 280, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 290, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 300, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 310, Train Acc: 0.97857, Val Acc: 0.74600, Test Acc: 0.71900\n","Epoch: 320, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 330, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 340, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 350, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 360, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 370, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 380, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 390, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 400, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 410, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 420, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 430, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 440, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 450, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 460, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 470, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 480, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n","Epoch: 490, Train Acc: 0.97857, Val Acc: 0.74400, Test Acc: 0.71900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GJiK0RV5_BPj"},"source":[""],"execution_count":null,"outputs":[]}]}